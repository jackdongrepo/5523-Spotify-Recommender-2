{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this cell to setup spotify account permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'display_name': 'wakizashi101',\n",
       " 'external_urls': {'spotify': 'https://open.spotify.com/user/wakizashi101'},\n",
       " 'followers': {'href': None, 'total': 10},\n",
       " 'href': 'https://api.spotify.com/v1/users/wakizashi101',\n",
       " 'id': 'wakizashi101',\n",
       " 'images': [],\n",
       " 'type': 'user',\n",
       " 'uri': 'spotify:user:wakizashi101'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.audio_methods import *\n",
    "import pandas as pd\n",
    "import time\n",
    "import spotipy\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "normalized_feature_stats = pd.read_csv(\"./data_frames/normalized_feature_stats.csv\",\n",
    "                                       usecols = range(0,10), index_col = 0)\n",
    "scope = 'playlist-modify-public'\n",
    "spuser = spotipy.Spotify(auth_manager=spotipy.SpotifyOAuth(scope=scope)) # requires different method of auth for user interaction\n",
    "spuser.current_user() # setup auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this cell for Kmeans. Can easily swap it out for a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans of K=400\n",
    "model = KMeans(n_clusters=400,random_state=5523).fit(normalized_feature_stats)\n",
    "# model = KMeans(n_clusters=400,random_state=5523).fit(train_pca)\n",
    "# DF of each track's clusters based on kmeans model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit the below function call for your recommendation upload based on a playlist. Increase the delay if you run into issues with a 429 error code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gathered 143 songs \n",
      "now fetching feature data. This may take a moment.\n",
      "280\n",
      "found 87 songs in cluster\n",
      "sorting by popularity\n",
      "87\n",
      "removing songs that you already know\n",
      "creating playlist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Should be uploaded'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_from_playlist(playlist_uri, pretrained_classifier, auth, name ,popularity='least', delay=5):\n",
    "    \"\"\"\n",
    "    Automatically uploads a recommended playlist based on the input song\n",
    "    \n",
    "    Inputs:\n",
    "    - playlist_uri, the uri of a playlist. right click a playlist, then share then copy spotify uri and that is your input\n",
    "    - pretrained_classifier, a trained classifier ready for predictions\n",
    "    - popularity='least', \n",
    "    - delay=1\n",
    "    \"\"\"\n",
    "    all_cluster_family = pd.DataFrame({\n",
    "    'track':normalized_feature_stats.index,\n",
    "    'cluster_id':pretrained_classifier.labels_\n",
    "    })\n",
    "    songs = getSongsFromPlaylist(playlist_uri, auth)\n",
    "    \n",
    "    if len(songs)==0:\n",
    "        print('No songs found in this playlist, dont confuse playlist with album')\n",
    "        return\n",
    "    print('gathered',len(songs),'songs','\\nnow fetching feature data. This may take a moment.')\n",
    "    \n",
    "    song_uris = []\n",
    "    for song in songs:\n",
    "        if song['track']['uri'] != None:\n",
    "            song_uris += [song['track']['uri']]\n",
    "            \n",
    "    feature_data_list = []\n",
    "    chunked_songs = [song_uris[i:i + 100] for i in range(0, len(song_uris), 100)]\n",
    "    for chunk in chunked_songs:\n",
    "        time.sleep(delay) # dont overwhelm api rate limit\n",
    "        features = getAudioFeaturesChunked(chunk)\n",
    "        feature_data_list+=features\n",
    "    to_be_removed = []\n",
    "    for i in range(len(feature_data_list)):\n",
    "        if feature_data_list[i] == None:\n",
    "            to_be_removed+=[i]      \n",
    "    for i in to_be_removed:\n",
    "        feature_data_list.pop(i)\n",
    "        \n",
    "    # Format features into df to prep for model prediction\n",
    "    base_track_features_df = pd.DataFrame.from_records(feature_data_list)[['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "    \n",
    "    # normalize features for prediction\n",
    "    # create new dataframe with lsited columns\n",
    "    mean_stats = pd.read_csv(\"./data_frames/normalized_features_mean.csv\",header = 0, index_col = 0, squeeze = True)\n",
    "    std_stats = pd.read_csv(\"./data_frames/normalized_features_std.csv\",header = 0, index_col = 0, squeeze = True)\n",
    "    normalized_base_track = (base_track_features_df-mean_stats)/std_stats\n",
    "\n",
    "    base_track_clusters = list(pretrained_classifier.predict(normalized_base_track))\n",
    "    freq = {} \n",
    "    for items in base_track_clusters: \n",
    "        freq[items] = base_track_clusters.count(items)\n",
    "        \n",
    "    base_track_cluster = max(freq, key=freq.get) # most common cluster\n",
    "        \n",
    "    print(base_track_cluster)\n",
    "    recommends = list(all_cluster_family[all_cluster_family.cluster_id == base_track_cluster].track) # does it work for other models?\n",
    "    print('found', len(recommends),'songs in cluster')\n",
    "    print('sorting by popularity')\n",
    "    recc_song_info = []\n",
    "    chunked_reccs = [recommends[i:i + 50] for i in range(0, len(recommends), 50)]\n",
    "    for chunk in chunked_reccs:\n",
    "        time.sleep(delay) # dont overwhelm api rate limit\n",
    "        recc_song_info+=getTrackBasicInfoChunked(chunk)\n",
    "    reverse = popularity!='least' # direction of sorting\n",
    "    sorted_recc = sorted(recc_song_info, key= lambda x:x['popularity'], reverse=reverse) # sort\n",
    "    print(len(sorted_recc))\n",
    "    new_playlist_songs = []\n",
    "    print('removing songs that you already know')\n",
    "    for song in sorted_recc:\n",
    "        if song['uri'] not in song_uris:\n",
    "            new_playlist_songs+=[song['uri']]\n",
    "    \n",
    "\n",
    "    if len(new_playlist_songs)==0:\n",
    "        print('you already have all of the music we were gonna recommend') # should not feasibly happen on larger datasets\n",
    "        return\n",
    "    print('creating playlist')\n",
    "    uploadRecommendationPlaylist(name, new_playlist_songs, delay, auth)\n",
    "    return 'Should be uploaded'\n",
    "\n",
    "recommend_from_playlist('spotify:playlist:1TfVViL8gm1bIGqQibq0Ys', model, spuser, 'kmeans clustering',delay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
